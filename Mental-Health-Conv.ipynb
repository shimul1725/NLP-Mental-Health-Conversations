{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f017ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32.1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "from transformers.utils import send_example_telemetry\n",
    "from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import ClassLabel, Sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3dcb098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm obsessing about a terrible breakup. Everyt...</td>\n",
       "      <td>The best way to move on is to give yourself su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am having a problem with extended family mem...</td>\n",
       "      <td>Hi, This sounds like a very challenging and up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think I have depression, anxiety, bipolar di...</td>\n",
       "      <td>It can be difficult to get counseling if you d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don’t love my sister. I would never wish her...</td>\n",
       "      <td>No one can force emotions.   Its fine to not l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When my daughter is stressed about a silly thi...</td>\n",
       "      <td>As parents, it's hard not to have \"freak out\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>We kissed and he grabbed my boobs and we excha...</td>\n",
       "      <td>The issue at hand here is that you're betrayal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I started dating a guy I met online. He told m...</td>\n",
       "      <td>Thank you for your question. Trust is a huge t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>What are the basic skills a good counselor nee...</td>\n",
       "      <td>1) An awareness of their own incompetence and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>What should I do when we see each other?</td>\n",
       "      <td>I am so sorry this happened.  Sharing a part o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>My husband and I have been married for seven y...</td>\n",
       "      <td>It's encouraging that you say you want \"to be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Context  \\\n",
       "0    I'm obsessing about a terrible breakup. Everyt...   \n",
       "1    I am having a problem with extended family mem...   \n",
       "2    I think I have depression, anxiety, bipolar di...   \n",
       "3    I don’t love my sister. I would never wish her...   \n",
       "4    When my daughter is stressed about a silly thi...   \n",
       "..                                                 ...   \n",
       "995  We kissed and he grabbed my boobs and we excha...   \n",
       "996  I started dating a guy I met online. He told m...   \n",
       "997  What are the basic skills a good counselor nee...   \n",
       "998           What should I do when we see each other?   \n",
       "999  My husband and I have been married for seven y...   \n",
       "\n",
       "                                              Response  \n",
       "0    The best way to move on is to give yourself su...  \n",
       "1    Hi, This sounds like a very challenging and up...  \n",
       "2    It can be difficult to get counseling if you d...  \n",
       "3    No one can force emotions.   Its fine to not l...  \n",
       "4    As parents, it's hard not to have \"freak out\" ...  \n",
       "..                                                 ...  \n",
       "995  The issue at hand here is that you're betrayal...  \n",
       "996  Thank you for your question. Trust is a huge t...  \n",
       "997  1) An awareness of their own incompetence and ...  \n",
       "998  I am so sorry this happened.  Sharing a part o...  \n",
       "999  It's encouraging that you say you want \"to be ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Context', 'Response']\n",
      "context\n",
      "I'm obsessing about a terrible breakup. Everything is a constant reminder.  How do I move on?\n",
      "\n",
      "response\n",
      "The best way to move on is to give yourself sufficient time and space away from your ex so you can heal.  That means no checking out your ex on social media platforms and no contact.  In order to move on and diminish the obsessions, help yourself recognize and accept that the relationship is over, and make sure to get sufficient support in processing all your feelings.  Once that takes place, it can be useful to explore and process with a professional the meaning of the relationship and to understand your part in what transpired.Sometimes people obsess because they have difficulties accepting what's already taken place and want things to be different.  The key to moving forward is to be loving toward yourself, to give yourself permission to grieve the loss, and to start cultivating new and healthy habits/patterns.  Reengage in your present life, ask yourself what you want your life to look like, and start creating goals and taking small steps to create the amazing life you want for yourself.  \n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('Data/train.csv')\n",
    "data=data.dropna()\n",
    "n=len(data)\n",
    "print(n)\n",
    "N=list(range(n))\n",
    "random.shuffle(N)\n",
    "data=data.iloc[N][0:1000].reset_index(drop=True)\n",
    "display(data)\n",
    "print(data.columns.tolist())\n",
    "print('context')\n",
    "print(data.iloc[0,0])\n",
    "print()\n",
    "print('response')\n",
    "print(data.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec3eb2",
   "metadata": {},
   "source": [
    "##### Model For ForCausalLM\n",
    "**roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b74ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "#from transformers.models.roberta.modeling_roberta import RobertaForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc968b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "class CustomModel(AutoModelForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config.max_position_embeddings = 514  # Set your desired size\n",
    "        self.max_sequence_length = 514  # Set the same value for consistency\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "                inputs_embeds=None, start_positions=None, end_positions=None, output_attentions=None,\n",
    "                output_hidden_states=None, return_dict=None):\n",
    "\n",
    "        # Check and truncate input_ids if necessary\n",
    "        if input_ids is not None and input_ids.size(1) > self.max_sequence_length:\n",
    "            input_ids = input_ids[:, :self.max_sequence_length]\n",
    "            \n",
    "        # Print the sizes of important tensors for debugging\n",
    "        print(\"Input_ids size:\", input_ids.size())\n",
    "        print(\"Attention_mask size:\", attention_mask.size() if attention_mask is not None else None)          \n",
    "\n",
    "        # Continue with the rest of the forward method\n",
    "        return super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    \n",
    "model_name = \"roberta-base\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = CustomModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1b134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.32.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14692d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForCausalLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659007ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(dataframe, tokenizer, max_sequence_length=512):\n",
    "    formatted_data = []\n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        input_text = f\"{row['Context']} \"\n",
    "        \n",
    "        if len(input_text) > max_sequence_length:\n",
    "            input_text = input_text[:max_sequence_length]\n",
    "\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=max_sequence_length, truncation=True)    \n",
    " \n",
    "        if 'Response' in row:\n",
    "            answer_text = row['Response']\n",
    "            answer_tokens = tokenizer(answer_text, return_tensors=\"pt\")[\"input_ids\"] \n",
    "        else:\n",
    "            answer_text, answer_tokens = None, None\n",
    "\n",
    "        formatted_data.append({\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            #'labels': answer_tokens,\n",
    "        })\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba3e81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   100,   437, 34668,   154,    59,    10,  6587, 21310,     4,\n",
      "          9567,    16,    10,  5891,  8306,     4,  1437,  1336,   109,    38,\n",
      "           517,    15,   116,  1437,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n"
     ]
    }
   ],
   "source": [
    "formatted_df = format_df(data, tokenizer)\n",
    "print(formatted_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1779d",
   "metadata": {},
   "source": [
    "#### CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcfc2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, formatted_data):\n",
    "        self.formatted_data = formatted_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.formatted_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.formatted_data[idx]['input_ids'].squeeze(),\n",
    "            'attention_mask': self.formatted_data[idx]['attention_mask'].squeeze(), \n",
    "            #'labels': self.formatted_data[idx]['labels'].squeeze() if self.formatted_data[idx]['labels'] is not None else None,\n",
    "            'start_positions': self.formatted_data[idx]['start_positions'] if 'start_positions' in self.formatted_data[idx] else None,\n",
    "            'end_positions': self.formatted_data[idx]['end_positions'] if 'end_positions' in self.formatted_data[idx] else None\n",
    "        }\n",
    "    \n",
    "n=len(formatted_df)\n",
    "trainset = CustomDataset(formatted_df[0:n*4//5])\n",
    "testset = CustomDataset(formatted_df[n*4//5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffbcee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True)\n",
    "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True)\n",
    "\n",
    "    #labels = pad_sequence([item['labels'] for item in batch if item['labels'] is not None], batch_first=True) if any(item['labels'] is not None for item in batch) else None\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        #'labels': labels,\n",
    "    }\n",
    "        \n",
    "batch_size = 8  \n",
    "\n",
    "train_dataloader = DataLoader(trainset, batch_size=batch_size, \n",
    "                              shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(testset, batch_size=batch_size, \n",
    "                              shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a60eaf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForCausalLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a879795",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45eddc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    #labels = batch['labels'].to(device) if batch['labels'] is not None else None\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask,)# labels=labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19798f8f",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebdf5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get the predicted token IDs\n",
    "        logits = outputs.logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Convert token IDs to tokens\n",
    "        predicted_tokens = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Extend the list of predictions\n",
    "        all_predictions.extend(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae1e1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shimu\\AppData\\Local\\Temp\\ipykernel_26828\\2262833351.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['predicted']=all_predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Alot of our choices have to do with what we ha...</td>\n",
       "      <td>I am so terrified of having sex anymore becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Wonderful!  I am so excited for you.  What a h...</td>\n",
       "      <td>I have always wanted to have a transition from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Hello. Being a teenager in our society today c...</td>\n",
       "      <td>I'm in my late teens and live with my dad.  Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>One key factor to consider is, are you able to...</td>\n",
       "      <td>I've only been married three months. Every wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Your situation sounds extremely frustrating.Yo...</td>\n",
       "      <td>My mother is combative with me when I say I do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The issue at hand here is that you're betrayal...</td>\n",
       "      <td>We kissed and he grabbed my boobs and we excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Thank you for your question. Trust is a huge t...</td>\n",
       "      <td>I started dating a guy I met online. He told m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1) An awareness of their own incompetence and ...</td>\n",
       "      <td>What are the basic skills a good counselor nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>I am so sorry this happened.  Sharing a part o...</td>\n",
       "      <td>What should I do when we see each other?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>It's encouraging that you say you want \"to be ...</td>\n",
       "      <td>My husband and I have been married for seven y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Response  \\\n",
       "800  Alot of our choices have to do with what we ha...   \n",
       "801  Wonderful!  I am so excited for you.  What a h...   \n",
       "802  Hello. Being a teenager in our society today c...   \n",
       "803  One key factor to consider is, are you able to...   \n",
       "804  Your situation sounds extremely frustrating.Yo...   \n",
       "..                                                 ...   \n",
       "995  The issue at hand here is that you're betrayal...   \n",
       "996  Thank you for your question. Trust is a huge t...   \n",
       "997  1) An awareness of their own incompetence and ...   \n",
       "998  I am so sorry this happened.  Sharing a part o...   \n",
       "999  It's encouraging that you say you want \"to be ...   \n",
       "\n",
       "                                             predicted  \n",
       "800  I am so terrified of having sex anymore becaus...  \n",
       "801  I have always wanted to have a transition from...  \n",
       "802  I'm in my late teens and live with my dad.  Th...  \n",
       "803  I've only been married three months. Every wee...  \n",
       "804  My mother is combative with me when I say I do...  \n",
       "..                                                 ...  \n",
       "995  We kissed and he grabbed my boobs and we excha...  \n",
       "996  I started dating a guy I met online. He told m...  \n",
       "997  What are the basic skills a good counselor nee...  \n",
       "998          What should I do when we see each other?   \n",
       "999  My husband and I have been married for seven y...  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shimu\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\shimu\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\shimu\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "## BLUE Score, Accuracy and F1 Score\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "test=data[n*4//5:]\n",
    "test['predicted']=all_predictions\n",
    "test=test[['Response','predicted']]\n",
    "#test_df['answer_text']=test_df['answers'].apply(lambda x:x.get('text',[''])[0])\n",
    "display(test)\n",
    "\n",
    "references=test['Response'].tolist()\n",
    "hypotheses =test['predicted'].tolist()\n",
    "\n",
    "bleu_score = corpus_bleu(references, hypotheses)\n",
    "#accuracy = accuracy_score(references, hypotheses)\n",
    "#f1 = f1_score(references, hypotheses, average='micro')\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "#print(f\"Accuracy: {accuracy:.4f}\")\n",
    "#print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29649053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      "Alot of our choices have to do with what we have been taught and partly our fear of trusting ourselves to do what is right. There is so much more going on within you than you realize. We can help you bring it to the surface. Please contact us when you can and in whatever way you can to discuss what's going on with you.\n",
      "\n",
      "predicted\n",
      "I am so terrified of having sex anymore because I have been told over and over that sex is dangerous even though me and my partner used both forms of protection. My partner is not happy about this and simply wants more sex, and honestly, I want to give that to her. \n"
     ]
    }
   ],
   "source": [
    "print('response')\n",
    "print(test.iloc[0,0])\n",
    "print()\n",
    "print('predicted')\n",
    "print(test.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864961f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
